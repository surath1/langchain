{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from constants import OPENAI_KEY\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_KEY, model_name=\"gpt-3.5-turbo-1106\", temperature=0.7)\n",
    "#llm = OpenAI(model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_youtube_video_url(video_url: str) -> FAISS:\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_db_from_youtube_video_url(\"https://www.youtube.com/watch?v=dlJQ-YiXgCs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the document say?\"\n",
    "docs = data.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"the first method that we have we added this really early on in Lang chain and it's been around ever since it's it's it was inspired by offer press's self- askk paper and it just prints out um the steps that happen um at at a highest level so we're not getting all the details but we're getting the high level of what's happening so if we set verose equals true here um and then recreate the agent and then we call it again we can see here that we have some nice printing of what exactly is going on so we're calling this tool with this search query we're getting back this response and then we're getting back this final answer and so again we're not seen all the information but we're seeing high level what steps are occurring so this is a good first pass we've added another method since then called debug equals true and this logs way more information and so it might be Overkill sometimes but other times it can be really helpful to see exactly what's going on so here we'll set verbose equals\", metadata={'source': 'dlJQ-YiXgCs'}),\n",
       " Document(page_content=\"equals false just to get rid of this noise and then we can run it and what's going to happen is in the background it's going to log everything to this Trace section here and then I can click into it and I can see the exact steps that occurred I can see so so here we're highlighting so as you notied with the Json there's a lot of events that are happening there's a lot of different formatting of prompts that are happening parsing that's happening um and so we have one view where you can see all of that you can click into the ones you can see uh uh what exactly the inputs are what exactly the outputs are um you can go into a playground experience and and edit it and play around with it there's a bunch of other functionality that's part of Lang Smith that I won't go into here but then we also have this most relevant run where we just show you the important events like API calls to llms retrieval calls tool calls things like that and so this is a really good way to see exactly what's\", metadata={'source': 'dlJQ-YiXgCs'}),\n",
       " Document(page_content=\"environment like this uh uh Jupiter notebook but when you're maybe not in this or when you want to persist these logs more or if you just want to explore these logs in a more intuitive way right this is this is a little bit of a dump of everything um then you're probably going to want a more uh full-fledged tool and and that's why we built Lang Smith um Lang Smith isn't the focus of uh this video or the uh uh launch of Lang chain 0.1 in general um but it's absolutely worth highlighting because Lang chain is built to be the most observable framework but we've also built tools along the side to make that a reality so with Lang Smith what we can do is we can go into lsmith we can go to our project we can just set these three environment variables um and so we can do that here and I'm going to pause the video and put in my API key so you don't see it I've done that now we can now set debug equals false just to get rid of this noise and then we can run it and what's going to happen is in\", metadata={'source': 'dlJQ-YiXgCs'}),\n",
       " Document(page_content=\"through a few of these different options let's take a look at what it looks like if we're using an agent without loging we'll go over agents in other sections of this tutorial but here we can construct it rather quickly and then we can invoke it and we'll see that it takes a little bit to respond under the hood and and we'll see this later on it's making a few different LM calls it's calling out to a search engine and so there's quite a bit of of uh API calls that are being made and so we get back a final output but we don't exactly know what happen happened inside and so that makes it tough to iterate on the prompts there's you know we're using an agent prompt here um there's uh the llm that we're using there's the output parser that we have and all of those can be tuned according to what we want to accomplish but in order to do that we have to understand exactly what's happening so the first method that we have we added this really early on in Lang chain and it's been around ever\", metadata={'source': 'dlJQ-YiXgCs'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Ask me about the video?\"\n",
    "docs = data.similarity_search(query, 4)\n",
    "docs_page_content = \" \".join([d.page_content for d in docs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"environment like this uh uh Jupiter notebook but when you're maybe not in this or when you want to persist these logs more or if you just want to explore these logs in a more intuitive way right this is this is a little bit of a dump of everything um then you're probably going to want a more uh full-fledged tool and and that's why we built Lang Smith um Lang Smith isn't the focus of uh this video or the uh uh launch of Lang chain 0.1 in general um but it's absolutely worth highlighting because Lang chain is built to be the most observable framework but we've also built tools along the side to make that a reality so with Lang Smith what we can do is we can go into lsmith we can go to our project we can just set these three environment variables um and so we can do that here and I'm going to pause the video and put in my API key so you don't see it I've done that now we can now set debug equals false just to get rid of this noise and then we can run it and what's going to happen is in the first method that we have we added this really early on in Lang chain and it's been around ever since it's it's it was inspired by offer press's self- askk paper and it just prints out um the steps that happen um at at a highest level so we're not getting all the details but we're getting the high level of what's happening so if we set verose equals true here um and then recreate the agent and then we call it again we can see here that we have some nice printing of what exactly is going on so we're calling this tool with this search query we're getting back this response and then we're getting back this final answer and so again we're not seen all the information but we're seeing high level what steps are occurring so this is a good first pass we've added another method since then called debug equals true and this logs way more information and so it might be Overkill sometimes but other times it can be really helpful to see exactly what's going on so here we'll set verbose equals equals false just to get rid of this noise and then we can run it and what's going to happen is in the background it's going to log everything to this Trace section here and then I can click into it and I can see the exact steps that occurred I can see so so here we're highlighting so as you notied with the Json there's a lot of events that are happening there's a lot of different formatting of prompts that are happening parsing that's happening um and so we have one view where you can see all of that you can click into the ones you can see uh uh what exactly the inputs are what exactly the outputs are um you can go into a playground experience and and edit it and play around with it there's a bunch of other functionality that's part of Lang Smith that I won't go into here but then we also have this most relevant run where we just show you the important events like API calls to llms retrieval calls tool calls things like that and so this is a really good way to see exactly what's observability is a key part of Lang chain and we've put a lot of focus into making L chain have the best observability as possible as you're building complex applications with language models whether it be really long sequences of chains or whether it be more agentic Behavior being able to understand exactly what's going on inside your application becomes really really important and even if you're working with simpler chains often times the prompts you construct come from many different sources and so being able to see exactly what the inputs to the language model are exactly what the outputs are and all the steps along the way is really really important to being able to iterate and improve your application and we've designed Lang chain to have a bunch of different options to make it incredibly observable and have a high level of observability into exactly what is going on so walking through a few of these different options let's take a look at what it looks like if we're using an\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Ask me about the video?\"\n",
    "docs = data.similarity_search(query, k=4)\n",
    "docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"docs\"],\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant that that can answer questions about youtube videos \n",
    "    based on the video's transcript.\n",
    "    \n",
    "    Answer the following question: {question}\n",
    "    By searching the following video transcript: {docs}\n",
    "    \n",
    "    Only use the factual information from the transcript to answer the question.\n",
    "    \n",
    "    If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "    \n",
    "    Your answers should be verbose and detailed.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chain.run(question=query, docs=docs_page_content)\n",
    "response = response.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have enough information to answer the question based on the provided transcript.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_query(llm, db, query, k=4):\n",
    "   \n",
    "   docs = db.similarity_search(query, k=4)\n",
    "   docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "   prompt = PromptTemplate(\n",
    "      input_variables=[\"question\", \"docs\"],\n",
    "      template=\"\"\"\n",
    "      You are a helpful assistant that that can answer questions about youtube videos \n",
    "      based on the video's transcript.\n",
    "      \n",
    "      Answer the following question: {question}\n",
    "      By searching the following video transcript: {docs}\n",
    "      \n",
    "      Only use the factual information from the transcript to answer the question.\n",
    "      \n",
    "      If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "      \n",
    "      Your answers should be verbose and detailed.\n",
    "      \"\"\",\n",
    "   )\n",
    "\n",
    "   chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "   response = chain.run(question=query, docs=docs_page_content)\n",
    "   response = response.replace(\"\\n\", \"\")\n",
    "   return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Ask me about the video?\"\n",
    "response, docs  = get_response_from_query(llm=llm, db=data, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but based on the provided transcript, I cannot answer the question as it is not clear what the video is about. The transcript seems to discuss a tool called Lang Smith and its features, but it does not provide specific details about the topic of the video. Therefore, I don't have enough information to accurately answer the question.\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Instantiation using from_template (recommended)\n",
    "#prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
    "#prompt.format(foo=\"bar\")\n",
    "\n",
    "# Instantiation using initializer\n",
    "prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say hi {foo}\")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hi, my name is Assistant. How can I help you today?'\n"
     ]
    }
   ],
   "source": [
    "#chain = prompt | llm\n",
    "#chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.invoke({\"foo\":\"what is your name\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'foo': {'title': 'Foo', 'type': 'string'}}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Justin Bieber was born on March 1, 1994. The president of the United States at that time was Bill Clinton, who was in office from January 20, 1993, to January 20, 2001.'\n"
     ]
    }
   ],
   "source": [
    "question = \"Who was the president in the year Justin Beiber was born?\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'question': {'title': 'Question', 'type': 'string'}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Youtube Vidio Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_db_from_youtube_video_url(\"https://www.youtube.com/watch?v=U6SddR1NnqY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x18bfeab3a90>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Ask me about the video?\"\n",
    "response, docs  = get_response_from_query(llm=llm, db=db, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video transcript discusses a variety of topics, including the demolition of temples and the construction of new ones, the worship of iconic figures, the concept of God, and the idea of belief systems. The speaker also addresses the historical and cultural significance of certain places and the impact of past wars on communities. Additionally, the speaker talks about the divisive nature of certain issues and the need for people to coexist peacefully despite their differing beliefs.The transcript does not provide a specific question to answer, but it does touch on the topic of the construction of temples and the significance of certain places. The speaker discusses the demolition of temples and the desire to build new ones, as well as the cultural and religious importance of these sites. The speaker also addresses the impact of past wars and the division between communities, emphasizing the need for peaceful coexistence.Overall, the transcript provides a deep insight into the cultural, historical, and religious aspects of the topics discussed. It highlights the complexity of these issues and the importance of understanding and respecting different perspectives.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
